import aiohttp
import feedparser
import logging
from typing import List, Dict
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)


class TrendScraper:
    """–°–±–æ—Ä —Ç—Ä–µ–Ω–¥–æ–≤ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    
    async def get_reddit_trends(self, subreddit: str = "blender") -> List[Dict]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤ –∏–∑ Reddit —á–µ—Ä–µ–∑ RSS
        
        Args:
            subreddit: –ù–∞–∑–≤–∞–Ω–∏–µ —Å–∞–±—Ä–µ–¥–¥–∏—Ç–∞
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø–æ—Å—Ç–∞–º–∏
        """
        try:
            url = f"https://www.reddit.com/r/{subreddit}/hot.rss"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as response:
                    if response.status == 200:
                        content = await response.text()
                        feed = feedparser.parse(content)
                        
                        posts = []
                        for entry in feed.entries[:5]:
                            posts.append({
                                "title": entry.title,
                                "link": entry.link,
                                "source": "Reddit"
                            })
                        return posts
        except Exception as e:
            logger.error(f"Reddit scraping error: {e}")
        
        return []
    
    async def get_youtube_trends(self) -> List[Dict]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –≤–∏–¥–µ–æ YouTube —á–µ—Ä–µ–∑ RSS
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –≤–∏–¥–µ–æ
        """
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º RSS –¥–ª—è –∫–∞–Ω–∞–ª–æ–≤ –æ 3D
            channels = [
                "UCOKHwx1VCdgnxwbjyb9Iu1g",  # Blender Guru
                "UCuNhGhbemBkdflZ1FGJ0lUQ",  # CG Geek
            ]
            
            videos = []
            
            async with aiohttp.ClientSession() as session:
                for channel_id in channels[:1]:  # –ë–µ—Ä–µ–º –æ–¥–∏–Ω –∫–∞–Ω–∞–ª, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å
                    url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
                    
                    try:
                        async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as response:
                            if response.status == 200:
                                content = await response.text()
                                feed = feedparser.parse(content)
                                
                                for entry in feed.entries[:3]:
                                    videos.append({
                                        "title": entry.title,
                                        "link": entry.link,
                                        "source": "YouTube"
                                    })
                    except Exception as e:
                        logger.error(f"YouTube channel error: {e}")
                        continue
            
            return videos
        
        except Exception as e:
            logger.error(f"YouTube scraping error: {e}")
        
        return []
    
    async def get_synthetic_trends(self) -> str:
        """
        Fallback: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–Ω–¥–æ–≤
        –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–µ–º –≤ 3D
        """
        synthetic = """
üåê –ê–ö–¢–£–ê–õ–¨–ù–´–ï –¢–ï–ú–´ –í 3D (–Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–∏—Ö —Ç—Ä–µ–Ω–¥–æ–≤):

1. AI –≤ 3D –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –≤ workflow
2. Procedural –º–∞—Ç–µ—Ä–∏–∞–ª—ã - —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç—É—Ä
3. Real-time —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥ –≤ Unreal Engine 5
4. Stylized 3D –ø–µ—Ä—Å–æ–Ω–∞–∂–∏ –¥–ª—è –∏–≥—Ä –∏ –∞–Ω–∏–º–∞—Ü–∏–∏
5. Virtual Production - 3D –¥–ª—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã—Ö —Å—ä–µ–º–æ–∫

üì± –ü–û–ü–£–õ–Ø–†–ù–´–ï –¢–ï–ú–´ –í –°–û–¶–°–ï–¢–Ø–•:
- Time-lapse –≤–∏–¥–µ–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Å–æ–∑–¥–∞–Ω–∏—è
- Breakdown —Å–ª–æ–∂–Ω—ã—Ö —Å—Ü–µ–Ω
- Tutorial –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º —Ç–µ—Ö–Ω–∏–∫–∞–º
- Before/After —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
- Behind the scenes

üéØ 3D –ù–ò–®–ò –° –í–´–°–û–ö–ò–ú ENGAGEMENT:
- –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
- Product design
- Character design
- Motion graphics
- NFT –∏ crypto art
        """
        return synthetic
    
    async def get_all_trends(self) -> str:
        """
        –°–±–æ—Ä –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤
        
        Returns:
            –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Å —Ç—Ä–µ–Ω–¥–∞–º–∏
        """
        result = "üîç –°–û–ë–†–ê–ù–ù–´–ï –¢–†–ï–ù–î–´:\n\n"
        
        # Reddit
        reddit_posts = await self.get_reddit_trends()
        if reddit_posts:
            result += "üì± REDDIT (r/blender):\n"
            for i, post in enumerate(reddit_posts, 1):
                result += f"{i}. {post['title']}\n"
            result += "\n"
        
        # YouTube
        youtube_videos = await self.get_youtube_trends()
        if youtube_videos:
            result += "üé• YOUTUBE:\n"
            for i, video in enumerate(youtube_videos, 1):
                result += f"{i}. {video['title']}\n"
            result += "\n"
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å–æ–±—Ä–∞–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ç–µ—Ç–∏–∫—É
        if not reddit_posts and not youtube_videos:
            result += await self.get_synthetic_trends()
        
        return result


class CompetitorScraper:
    """–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞—Ö"""
    
    async def analyze_username(self, username: str, platform: str = "twitter") -> str:
        """
        –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ñ–∏–ª—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞
        
        –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –†–µ–∞–ª—å–Ω—ã–π —Å–∫—Ä–∞–ø–∏–Ω–≥ —Ç—Ä–µ–±—É–µ—Ç API –∫–ª—é—á–µ–π.
        –ó–¥–µ—Å—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏.
        
        Args:
            username: –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            platform: –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ (twitter/youtube/threads)
        
        Returns:
            –°—Ç—Ä–æ–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        """
        
        # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –∑–¥–µ—Å—å –±—ã–ª –±—ã —Ä–µ–∞–ª—å–Ω—ã–π API –∑–∞–ø—Ä–æ—Å
        # –°–µ–π—á–∞—Å —Å–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        
        synthetic_data = f"""
üìä –ü–†–û–§–ò–õ–¨: @{username} ({platform})

–ü–†–ò–ú–ï–†–´ –ü–û–°–¢–û–í (—Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏):

–ü–æ—Å—Ç 1: "Just finished this cyberpunk character in Blender üíú #3D #blender"
- –õ–∞–π–∫–∏: 1.2K
- –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏: 45
- –§–æ—Ä–º–∞—Ç: Image + text

–ü–æ—Å—Ç 2: "Time-lapse of my latest environment üåÜ Full tutorial coming soon!"
- –õ–∞–π–∫–∏: 2.3K
- –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏: 78
- –§–æ—Ä–º–∞—Ç: Video

–ü–æ—Å—Ç 3: "Breaking down my shader setup for realistic skin ‚ú®"
- –õ–∞–π–∫–∏: 890
- –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏: 34
- –§–æ—Ä–º–∞—Ç: Carousel/Thread

–ü–ê–¢–¢–ï–†–ù–´:
- –ü–æ—Å—Ç–∏—Ç 3-4 —Ä–∞–∑–∞ –≤ –Ω–µ–¥–µ–ª—é
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —ç–º–æ–¥–∑–∏
- –ß–∞—Å—Ç–æ –¥–µ–ª–∞–µ—Ç time-lapse –≤–∏–¥–µ–æ
- –ê–∫—Ç–∏–≤–µ–Ω —Å tutorial –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
- –•–µ—à—Ç–µ–≥–∏: #3D #Blender #3DArt #CGI

–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –≠—Ç–æ –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ. –î–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–¥–∫–ª—é—á–∏—Ç–µ API –Ω—É–∂–Ω–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã.
        """
        
        return synthetic_data


# Singleton —ç–∫–∑–µ–º–ø–ª—è—Ä—ã
trend_scraper = TrendScraper()
competitor_scraper = CompetitorScraper()
